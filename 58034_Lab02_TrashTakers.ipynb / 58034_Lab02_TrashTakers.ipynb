{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "58034_Lab02_TrashTakers",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kezamamio/CpE-AIML/blob/main/58034_Lab02_TrashTakers.ipynb%20/%2058034_Lab02_TrashTakers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fte_zsqVdp8R"
      },
      "source": [
        "# Topic02a : Prelim Problem Set I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpcY5oJ5eFxA"
      },
      "source": [
        "## Case 1\n",
        "Represent the following representations into its vectorized form using LaTeX.\n",
        "> **Problem 1.a. System of Linear Equations**\n",
        "$$\n",
        "\\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        -y+z=\\frac{1}{32}\\\\ \n",
        "        \\frac{1}{2}x -2y=0 \\\\\n",
        "        -x + \\frac{3}{7}z=\\frac{4}{5}\n",
        "    \\end{array}\n",
        "\\right. $$\n",
        "> **Problem 1.b. Linear Combination**\n",
        "$$  \\cos{(\\theta)}\\hat{i} + \\sin{(\\theta)}\\hat{j} - \\csc{(2\\theta)}\\hat{k}$$\n",
        "> **Problem 1.c. Scenario**\n",
        ">\n",
        ">A conference has 200 student attendees, 45 professionals, and has 15 members of the panel. There is a team of 40 people on the organizing committee. Represent the *percent* composition of each *attendee* type of the conference in matrix form.\n",
        "\n",
        "Express your answers in LaTeX in the answer area.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHm7yBG6FrWJ"
      },
      "source": [
        "###Answer to Problem 1.a: System of Linear Equations\n",
        "\n",
        "> Let the vectorized form be solved using the equation $r = X^{-1}Y$ wherein, we're solving for $r$ or simply solving for $x,y,$and$z$.\n",
        "\n",
        "> Wherein, $X$ is $\\begin{bmatrix}0 & -1 &1 \\\\ 1/2 &-2 &0 \\\\ -1 & 0 & 3/7 \\end{bmatrix}$,  $r$ is $\\begin{bmatrix}x\\\\ y\\\\ z\\end{bmatrix}$, and $Y$ is $\\begin{bmatrix}1/32\\\\0\\\\4/5\\end{bmatrix}$.\n",
        "\n",
        "**Matrix**\n",
        "> This is the matrix equivalent of the given form.\n",
        "\n",
        "$$\\begin{bmatrix}0 & -1 &1 \\\\ 1/2 &-2 &0 \\\\ -1 & 0 & 3/7 \\end{bmatrix} \\cdot\\begin{bmatrix} x\\\\y\\\\z\\end{bmatrix} = \\begin{bmatrix}1/32\\\\0\\\\4/5\\end{bmatrix}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtAjJY7yeS5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2eaaf2b-5105-491f-a04d-493c4966c55e"
      },
      "source": [
        "### Problem 1.a\n",
        "import numpy as np\n",
        "import fractions\n",
        "from fractions import Fraction\n",
        "\n",
        "X = np.array([\n",
        "    [0,-1, 1],\n",
        "    [Fraction(1,2),-2,0],\n",
        "    [-1, 0, Fraction(3,7)]\n",
        " ], dtype=float)\n",
        "\n",
        "Y = np.array([\n",
        "    [Fraction(1,32)],\n",
        "    [0],\n",
        "    [Fraction(4,5)]\n",
        "], dtype=float)\n",
        "\n",
        "X_inv = np.linalg.inv(X)\n",
        "np.set_printoptions(formatter={'all':lambda x: str(fractions.Fraction(x).limit_denominator())})\n",
        "X_inv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12/25, -6/25, -28/25],\n",
              "       [3/25, -14/25, -7/25],\n",
              "       [28/25, -14/25, -7/25]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWnQRIVGMTbI"
      },
      "source": [
        "> This is the answer when computing for the inverse of the matrix.\n",
        "\n",
        "$$\\begin{bmatrix}12/25 & -6/25 & -28/25 \\\\ 3/25 & -14/25 & -7/25 \\\\ 28/25 & -14/25 & -7/25 \\end{bmatrix}$$\n",
        "\n",
        "> The answer for vector $r$. \n",
        "$$r =\\begin{bmatrix}-881/1000\\\\-881/4000\\\\-189/1000\\end{bmatrix}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHCoV1q0cDDG",
        "outputId": "4c85c585-d518-4902-bca8-7d1d43b5340d"
      },
      "source": [
        "r = X_inv @ Y\n",
        "r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-881/1000],\n",
              "       [-881/4000],\n",
              "       [-189/1000]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESq5xWu-Lco4"
      },
      "source": [
        "###Answer to Problem 1.b: Linear Combination\n",
        "\n",
        ">Suppose that vector A is,$$ A= \\cos{(\\theta)}\\hat{i} + \\sin{(\\theta)}\\hat{j} - \\csc{(2\\theta)}\\hat{k}$$\n",
        "\n",
        ">then the matrix equivalent is:\n",
        "$$ A = \\begin{bmatrix} cos{\\theta} & \\sin{\\theta} & -\\csc{2\\theta} \\end{bmatrix}$$\n",
        "\n",
        "\n",
        "> In this scenario, let us suppose that the value of theta $θ$ is $π/4$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFh3XKFCUuWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1203b191-d1a5-4b77-fa3e-15137ec7e3af"
      },
      "source": [
        "import numpy as np\n",
        "π = np.pi\n",
        "θ = π/4\n",
        "\n",
        "A = np.array([np.cos(θ), np.sin(θ), -np.arcsin(θ**2)])\n",
        "print(A)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.70710678  0.70710678 -0.66473461]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdJSUtPWLfGc"
      },
      "source": [
        "###Answer to Problem 1.c: Scenario\n",
        "\n",
        ">Let, $a$, $b$, $c$ and $d$ represent the type of people inside the conference.\n",
        "\n",
        "$$\\\\ a = 200 \\text{ students }, b = 45 \\text{ professionals},c = 15 \\text{ members of panel}, d = 40 \\text{ organizing committee}$$ \n",
        "\n",
        ">Since the only ones asked are the attendees, we take only the students, professionals, and the panel members in the equation. We leave the members organizing committe as they are not considered as attendees, but rather, organizers. Let,\n",
        "\n",
        "$$X = 200a + 45b + 15c$$\n",
        "\n",
        ">then, the matrix equivalent is:\n",
        "$$ \\begin{bmatrix} 200/260 & 45/260 & 15/260 \\end{bmatrix} \\cdot\\begin{bmatrix} a\\\\b\\\\c\\end{bmatrix} = \\begin{bmatrix} 1\\end{bmatrix}$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvb1MGs9QNVt"
      },
      "source": [
        "# Case 2\n",
        "> **Problem 2.a: Vector Magnitude**\n",
        "\n",
        ">The magnitude of a vector is usually computed as:\n",
        "$$||v|| = \\sqrt{a_0^2 + a_1^2 + ... +a_n^2}$$\n",
        "Whereas $v$ is any vector and $a_k$ are its elements wherein $k$ is the size of $v$.\n",
        "Re-formulate $||v||$ as a function of an inner product. Further discuss this concept and provide your user-defined function.\n",
        "\n",
        "> **Problem 2.b: Angle Between Vectors**\n",
        "\n",
        "> Inner products can also be related to the Law of Cosines. The property suggests that:\n",
        "$$u\\cdot v = ||u||\\cdot||v||\\cos(\\theta)$$\n",
        "Whereas $u$ and $v$ are vectors that have the same sizes and $\\theta$ is the angle between $u$ and $v$.\n",
        "\n",
        "> Explain the behavior of the dot product when the two vectors are perpendicular and when they are parallel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJd9LCmrSbjg"
      },
      "source": [
        "###Answer to Problem 2.a: Vector Magnitude\n",
        "\n",
        "> Consider vector $v$\n",
        "$$||v|| = \\begin{bmatrix} \n",
        "1, 2, 3, 4\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "> If we get the *inner product* of $v$ to itself, then:\n",
        "$$v \\cdot v = \\begin{bmatrix} \n",
        "1, 2, 3, 4\\\\ \n",
        "\\end{bmatrix} \\cdot \n",
        "\\begin{bmatrix} \n",
        "1, 2, 3, 4\\\\ \n",
        "\\end{bmatrix}$$\n",
        "\n",
        "$$v \\cdot  v = \\begin{bmatrix}\n",
        "{(1 \\cdot 1) + (2 \\cdot 2) + (3 \\cdot 3) + (4 \\cdot 4)}\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "$$v \\cdot  v = \\begin{bmatrix}\n",
        "{1^2 + 2^2 + 3^2 + 4^2}\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "> The equation above is equivalent to finding the length or magnitude of a vector. We can write the definition of length in terms of the inner product:\n",
        "\n",
        "$$||v|| = \\sqrt{v \\cdot  v}$$ \n",
        "\n",
        "> With further simplification (square both sides), the new length definition of a vector becomes:\n",
        "\n",
        "$$||v||^2 = v \\cdot  v$$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz7AX837SdtS",
        "outputId": "9034f4ef-5734-43f8-d1cd-9c9e02e808bc"
      },
      "source": [
        "### Code to Problem 2.a\n",
        "import numpy as np\n",
        "\n",
        "## define vector v\n",
        "v = np.array([1, 2, 3, 4])\n",
        "\n",
        "## user-defined function\n",
        "def innerProd (x):\n",
        "  sum = 0\n",
        "  for i in range (len(x)):\n",
        "    sum += x[i] * x[i]\n",
        "  return sum\n",
        "\n",
        "## v dot v (v dot product to itself)\n",
        "product = innerProd(v)\n",
        "print(\"v dot v = \", product)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v dot v =  30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAFShkEmSorF"
      },
      "source": [
        "###Answer to Problem 2.b: Angle between Vectors\n",
        "\n",
        "**Perpendicular**: Two vectors are said to be perpendicular if the result of their ***dot product is 0***. The angle between them is *90 degrees*.\n",
        "\n",
        "Consider vectors $u$ and $v$\n",
        "$$u = \\begin{bmatrix} \n",
        "1, -3 \\\\ \n",
        "\\end{bmatrix} \n",
        "$$\n",
        "\n",
        "$$v =\\begin{bmatrix} \n",
        "6, 2 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "The dot product is as follows:\n",
        "\n",
        "$$u\\cdot v = (1 \\cdot 6) + (-3 \\cdot 2)$$\n",
        "\n",
        "$$u\\cdot v = 6 - 6 = 0$$\n",
        "\n",
        "**Parallel**: If vectors are ***multiples of each other***, they are said to be parallel. The angles between them lies on *0 or 180 degrees*.\n",
        "\n",
        "Consider vectors $y$ and $z$\n",
        "$$y = \\begin{bmatrix} \n",
        "5, 2 \\\\ \n",
        "\\end{bmatrix} \n",
        "$$\n",
        "\n",
        "$$z =\\begin{bmatrix} \n",
        "25, 10 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Then, $z$ can be expressed as: \n",
        "\n",
        "$$z = 5y$$\n",
        "\n",
        "Another way to confirm if vectors are parallel is by finding the angle between the two vectors using ***dot product*** and ***vector magnitude***.\n",
        "\n",
        "$$\\theta = \\arccos\\left(\\frac{\\mathbf{y}\\cdot\\mathbf{z}}{\\|\\mathbf{y}\\|\\|\\mathbf{z}\\|}\\right)$$\n",
        "\n",
        "Substituting the values we will get:\n",
        "\n",
        "$$\\theta = \\arccos\\left(\\frac{{145}}{\\|\\mathbf{\\sqrt{29}}\\|\\|\\mathbf{\\sqrt{725}}\\|}\\right)$$\n",
        "\n",
        "$$\\theta = 0$$\n",
        "\n",
        "Therefore, they are parallel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dWZSuFQS2Oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ff6fac-36c7-41c0-bc1a-35be356f961c"
      },
      "source": [
        "### Code to Problem 2.b (Perpendicular)\n",
        "import numpy as np\n",
        "\n",
        "u = np.array([1, -3])\n",
        "v = np.array([6, 2])\n",
        "\n",
        "def innerProd (a, b):\n",
        "  sum = 0\n",
        "  for i in range (len(a)):\n",
        "    sum += a[i] * b[i]\n",
        "  return sum\n",
        "\n",
        "product = innerProd(u, v)\n",
        "print(\"u dot v = \", product)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "u dot v =  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvzHI7zLyExX",
        "outputId": "38e013a5-f747-4e45-ba19-c19fdba3870b"
      },
      "source": [
        "### Code to Problem 2.b (Parallel)\n",
        "import numpy as np\n",
        "\n",
        "y = np.array([5, 2])\n",
        "z = np.array([25, 10])\n",
        "\n",
        "def innerProd (a, b):\n",
        "  sum = 0\n",
        "  for i in range (len(a)):\n",
        "    sum += a[i] * b[i]\n",
        "  return sum\n",
        "\n",
        "product = innerProd(y, z)\n",
        "print(\"y dot z = \", product)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y dot z =  145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cH8JpkBj1xS"
      },
      "source": [
        "# Case 3\n",
        "For the final cases analysis we will be looking at series of equations building up a single feed-forward computation of a logistic regression. The case will not require you to learn fully what is logistic regression. \n",
        "\n",
        "$$X = \\begin{bmatrix} \n",
        "— (x^{(1)})^T— \\\\ \n",
        "— (x^{(2)})^T— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T— \\\\\n",
        "\\end{bmatrix} \\text{, } \n",
        "Y = \\begin{bmatrix} \n",
        "y^{(1)} \\\\ \n",
        "y^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "y^{(m)} \\\\\n",
        "\\end{bmatrix} \\text{, and } \n",
        "\\theta = \\begin{bmatrix} \n",
        "\\theta^{(1)} \\\\ \n",
        "\\theta^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} $$\n",
        "The dataset $X$ has $m$ entries with $n$ features while $Y$ is the vector containing the ground truths of a the entries of $X$, and $\\theta$ are the parameters or weights of the vectors. We first compute the vector product of the dataset and the parameters as:\n",
        "$$ z = x^{(i)}\\theta^{(i)} = X\\cdot \\theta\\\\_{\\text{Eq. 3.1}}$$\n",
        "We then solve for the hypothesis of the logistic regression alogrithm as:\n",
        "\n",
        "$$ h_\\theta(x) = g(z)\\\\_{\\text{Eq. 3.2}}$$\n",
        "\n",
        "Where $g$ is an activation function that maps the values of the hypothesis vector between a range of 0 and 1. We computed the activation as a sigmoid function:\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}\\\\_{\\text{Eq. 3.3}}$$\n",
        "Finally we compute the loss of the logistic regression algorithm using $J$. Wheras $J(\\theta)$ is a function that computes the logistic loss of the hypothesis with respect to the ground truths $y$. it is then computed as:\n",
        "$$J(\\theta) = \\frac{1}{m} \\sum^m_{i=0}=[-y^{(i)}\\log({h_{\\theta}(x^{(i)})})-(1-y^{(i)})\\log(1-h_{\\theta}(x^{(i)}))]\\\\_{\\text{Eq. 3.4}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ8jJV9-qyFy"
      },
      "source": [
        "> **Problem 3.a: Matrix Equivalences**\n",
        "\n",
        "> In Eq. 1, $z$ can also be solved as $X \\cdot \\theta$ which is the vectorized form of $x^{(i)}\\theta^{(i)}$. However, it can also be expressed as $\\theta^T\\cdot X$. Prove the equality of $X \\cdot \\theta$ with $\\theta^T\\cdot X$ in this case.\n",
        "\n",
        "> **Problem 3.b: Matrix Shapes**\n",
        "\n",
        "> Determine the shape of $h_\\theta$ if $X$ has a shape of $(300,5)$.\n",
        "\n",
        "> **Problem 3.c: Vectorization**\n",
        "\n",
        "> Express $J(\\theta)$ into its vectorized form.\n",
        "\n",
        "> **Problem 4.c: Computational Programming (Also Laboratory 2)**\n",
        "\n",
        "> Encode Equations 3.1 to 3.4 as the class `LRegression` wherein:\n",
        "\n",
        "> * `LRegression` should be instantiated with a dataset $X$, a ground truth vector $y$, and a parameter vector $\\theta$. Each parameter should have a data type of `numpy.array`.\n",
        "> * It should further have `methods`reflecting to at least the four (4) aforementioned equations. Each should have a return value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_bDKk9TpCol"
      },
      "source": [
        "### **Answer for Problem 3.a**\n",
        "\n",
        "Performing the vector product of $X \\cdot \\theta$  will result as:\n",
        "\n",
        "$$z = \\begin{bmatrix} \n",
        "(x^{(1)})^T\\theta^{(1)}\\\\(x^{(2)})^T\\theta^{(2)}\\\\\\vdots\\\\(x^{(m)})^T\\theta^{(m)} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Determining the transpose vector of $\\theta$ will produce:\n",
        "\n",
        "$$\\theta^T = \\begin{bmatrix}\n",
        "(\\theta^{(1)})^T\\\\(\\theta^{(2)})^T\\\\\\vdots\\\\(\\theta^{(m)})^T\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Performing the vector product of $\\theta^T \\cdot X$ will result as:\n",
        "\n",
        "$$z = \\begin{bmatrix} \n",
        "(\\theta^{(1)})^T(x^{(1)})^T\\\\(\\theta^{(2)})^T(x^{(2)})^T\\\\\\vdots\\\\(\\theta^{(m)})^T(x^{(m)})^T\\\\\n",
        "\\end{bmatrix} \n",
        "$$\n",
        " \n",
        "Having a generalized form of:\n",
        "\n",
        "$$\\theta^T\\cdot X$$\n",
        "\n",
        "Hence, looking back at both equations:\n",
        "\n",
        "$$z = \\begin{bmatrix} \n",
        "(x^{(1)})^T\\theta^{(1)}\\\\(x^{(2)})^T\\theta^{(2)}\\\\\\vdots\\\\(x^{(m)})^T\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} \\text { = }\n",
        "\\begin{bmatrix} \n",
        "(\\theta^{(1)})^T(x^{(1)})^T\\\\(\\theta^{(2)})^T(x^{(2)})^T\\\\\\vdots\\\\(\\theta^{(m)})^T(x^{(m)})^T\\\\\n",
        "\\end{bmatrix} \n",
        "$$\n",
        "\n",
        "Thus, the equality of the statement $X \\cdot \\theta = \\theta^T\\cdot X$ is true."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7dbM1BJuOYt"
      },
      "source": [
        "### **Answer to Problem 3.b**\n",
        "Performing the dot product of matrices requires the first matrix's number of columns equal to the second matrix's number of rows. In this case: $$X = (300, 5) \\\\ \\theta = (5, 1)$$\n",
        "\n",
        "Assuming the matrix $\\theta$ is a column matrix, it has a $(5, 1)$ shape and its row is equal to the number of columns of the $X$ dataset. \\\\\n",
        "\n",
        "Then, $h_\\theta = X \\cdot \\theta$\n",
        "\n",
        "Thus, the shape of $h_\\theta$ is $(300, 1)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N48XwhZL6-4K"
      },
      "source": [
        "### **Answer to Problem 3.c**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t618n7IS7Dt_"
      },
      "source": [
        "Vectorized form of $J(\\theta)$ :\n",
        "$$J(\\theta) = \\frac{1}{m} \\cdot(-y^{T}\\log(h_{\\theta})-(1-y)^{T}\\log(1-h_{\\theta}))$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXAcqylkG7K-"
      },
      "source": [
        "###**Answer to Case 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZavabwIUHK7P"
      },
      "source": [
        "class LRegression:\n",
        "  def __init__(self,X,Y,theta):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    self.theta = theta\n",
        "    self.Z=None\n",
        "    self.g=None\n",
        "    self.J=None\n",
        "\n",
        "  def get_vectorproduct(self):\n",
        "    self.Z = np.dot(self.X,self.theta)\n",
        "    return self.Z\n",
        "\n",
        "  def get_shapeh(self):\n",
        "    return self.Z.shape\n",
        "\n",
        "  def get_hypothesis(self):\n",
        "    zexp = np.exp(-(self.Z))\n",
        "    self.g = 1 / (1+zexp)\n",
        "    return self.g\n",
        "\n",
        "  def get_loss(self):\n",
        "    firstpart = (-1*(self.Y.T))*(np.log(self.g))\n",
        "    secondpart = ((1-Y).T)*(np.log(1-self.g))\n",
        "    thirdpart = (firstpart-secondpart)\n",
        "    self.J = np.mean(thirdpart)\n",
        "    return self.J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12wBmWKnHOJR",
        "outputId": "fa0b4a3f-3a99-4dad-a1ce-65ec9d64d112"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.random.normal(0,1,size=(5,10)).T\n",
        "m = X.shape[1]\n",
        "theta = np.random.normal(0,1,size=(m,1))\n",
        "Y = np.random.randint(2,size=(m,1))\n",
        "print(X)\n",
        "print(theta)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.40810334  0.73196693  1.56365301 -0.96188213 -0.67084772]\n",
            " [ 0.83576972 -0.44988954  0.93655164  1.64625867  0.36934559]\n",
            " [-0.3826615   0.22401622 -0.44073071  0.48348971 -1.16716552]\n",
            " [ 1.1804394  -0.01992631 -0.81850534 -0.18827069 -1.47601995]\n",
            " [ 0.25491689 -0.78544156 -0.20619438 -0.47171802  2.42270301]\n",
            " [-0.21628769 -0.83016081 -0.70690263  2.06601923 -0.69557865]\n",
            " [-1.11260668 -0.68255937 -0.54888195  0.8542802  -0.18689897]\n",
            " [ 0.91234955 -0.35129994  1.31268653 -1.56133915  0.08154536]\n",
            " [-1.23501467  0.65339664 -0.60400562  0.12813037 -1.14836363]\n",
            " [-0.37123474 -1.31954555  0.35098363 -0.15923855  1.22400868]]\n",
            "[[ 0.08368961]\n",
            " [-2.02044799]\n",
            " [-1.40897972]\n",
            " [-0.42933591]\n",
            " [ 1.14787936]]\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3P6zpqjHQTT",
        "outputId": "bd7cf40a-5483-4501-cb38-85516816a808"
      },
      "source": [
        "Logit_test = LRegression(X,Y,theta)\n",
        "print(\"Vector product of X and theta: \\n\",Logit_test.get_vectorproduct())\n",
        "print(\"\\nShape of hypothesis:\",Logit_test.get_shapeh())\n",
        "print(\"\\nHypothesis of the Logistic Regression:\\n\",Logit_test.get_hypothesis())\n",
        "print(\"\\nLoss of the Logistic Regression:\\n\",Logit_test.get_loss())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector product of X and theta: \n",
            " [[-4.07329222]\n",
            " [-0.62349241]\n",
            " [-1.41100198]\n",
            " [-0.32115347]\n",
            " [ 4.88229768]\n",
            " [ 0.96975054]\n",
            " [ 1.478015  ]\n",
            " [-0.29946806]\n",
            " [-1.94567404]\n",
            " [ 3.61385698]]\n",
            "\n",
            "Shape of hypothesis: (10, 1)\n",
            "\n",
            "Hypothesis of the Logistic Regression:\n",
            " [[0.01673638]\n",
            " [0.34898757]\n",
            " [0.19607607]\n",
            " [0.42039466]\n",
            " [0.99247744]\n",
            " [0.72506977]\n",
            " [0.81427257]\n",
            " [0.42568753]\n",
            " [0.12502583]\n",
            " [0.97375941]]\n",
            "\n",
            "Loss of the Logistic Regression:\n",
            " 1.2494980127630797\n"
          ]
        }
      ]
    }
  ]
}